from pyspark.sql.functions import col
from pyspark.sql.types import IntegerType, DoubleType, BooleanType, DateType

configs = {"fs.azure.account.auth.type": "OAuth",
"fs.azure.account.oauth.provider.type": "org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider",
"fs.azure.account.oauth2.client.id": "cefb99c4-9578-436e-b050-a21e37bc395d",
"fs.azure.account.oauth2.client.secret": '4qy8Q~t7GJ9-FcM1T92_Z4R6nblQII5biTgECbha',
"fs.azure.account.oauth2.client.endpoint": "https://login.microsoftonline.com/c9e30403-6a97-4106-b079-a8068f5fef3a/oauth2/token"}

dbutils.fs.mount(
source = "abfss://tokyo-olympic-data2@tokyoolympicdataluke2.dfs.core.windows.net",
mount_point = "/mnt/tokyoolympic",
extra_configs = configs)
